{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "parser = argparse.ArgumentParser()\n",
    "    # dataset part\n",
    "parser.add_argument('--data_dir', type=str, default='Food-Kitchen', help='Movie-Book, Entertainment-Education')\n",
    "\n",
    "# model part\n",
    "parser.add_argument('--model', type=str, default=\"C2DSR\", help='model name')\n",
    "parser.add_argument('--hidden_units', type=int, default=128, help='lantent dim.')\n",
    "parser.add_argument('--num_blocks', type=int, default=2, help='lantent dim.')\n",
    "parser.add_argument('--num_heads', type=int, default=1, help='lantent dim.')\n",
    "parser.add_argument('--GNN', type=int, default=1, help='GNN depth.')\n",
    "parser.add_argument('--dropout', type=float, default=0.2, help='dropout rate.')\n",
    "parser.add_argument('--optim', choices=['sgd', 'adagrad', 'adam', 'adamax'], default='adam', help='Optimizer: sgd, adagrad, adam or adamax.')\n",
    "parser.add_argument('--param_group', type = bool, default=False, help='param group')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Applies to sgd and adagrad.')\n",
    "parser.add_argument('--lr_decay', type=float, default=1, help='Learning rate decay rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4, help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--decay_epoch', type=int, default=5, help='Decay learning rate after this epoch.')\n",
    "parser.add_argument('--max_grad_norm', type=float, default=5.0, help='Gradient clipping.')\n",
    "parser.add_argument('--leakey', type=float, default=0.1)\n",
    "parser.add_argument('--maxlen', type=int, default=50)\n",
    "parser.add_argument('--cpu', action='store_true', help='Ignore CUDA.')\n",
    "parser.add_argument('--cuda', type=bool, default=torch.cuda.is_available(), help='Enables CUDA training.')\n",
    "parser.add_argument('--lambda', type=float, default=0.7)\n",
    "\n",
    "# train part\n",
    "parser.add_argument('--num_epoch', type=int, default=100, help='Number of total training epochs.')\n",
    "parser.add_argument('--batch_size', type=int, default=256, help='Training batch size.')\n",
    "parser.add_argument('--log_step', type=int, default=200, help='Print log every k steps.')\n",
    "parser.add_argument('--log', type=str, default='log.txt', help='Write training log to file.')\n",
    "parser.add_argument('--save_epoch', type=int, default=100, help='Save model checkpoints every k epochs.')\n",
    "parser.add_argument('--save_dir', type=str, default='./saved_models', help='Root dir for saving models.')\n",
    "parser.add_argument('--id', type=str, default=00, help='Model ID under which to save models.')\n",
    "parser.add_argument('--seed', type=int, default=2023)\n",
    "parser.add_argument('--load', dest='load', action='store_true', default=False,  help='Load pretrained model.')\n",
    "parser.add_argument('--model_file', type=str, help='Filename of the pretrained model.')\n",
    "parser.add_argument('--info', type=str, default='', help='Optional info for the experiment.')\n",
    "parser.add_argument('--undebug', action='store_false', default=True)\n",
    "\n",
    "# data augmentation\n",
    "parser.add_argument('--augment_type', type=str, default=\"crop\", help='augment type')\n",
    "parser.add_argument('--crop_prob', type=float, default=0.8, help='crop probability')\n",
    "parser.add_argument('--mask_prob', type=float, default=0.2, help='mask probability')\n",
    "# time ssl\n",
    "parser.add_argument('--window_size',type=int,default=3 ,help=\"window size for ssl\")\n",
    "parser.add_argument('--temp',type=float,default=0.05 ,help=\"temperature for ssl\")\n",
    "parser.add_argument('--ssl',type=str ,default=\"augmentation_based_CL\" ,help=\"[time_CL, augmentation_based_CL, no_ssl, proto_CL]\")\n",
    "#early stop\n",
    "parser.add_argument('--patience',type=int,default=5 ,help=\"early stop counter\")\n",
    "\n",
    "parser.add_argument('--pooling',type=str,default=\"ave\" ,help=\"pooling method\")\n",
    "parser.add_argument('--is_pooling',type=bool,default=True ,help=\"pooling or not\")\n",
    "\n",
    "#MoCo\n",
    "parser.add_argument('--r',type=int,default=1280 ,help=\"queue size/negative sample\") #warning : r must be divisible by batch_size\n",
    "parser.add_argument('--m',type=float,default=0.999 ,help=\"momentum update ratio for moco\")\n",
    "parser.add_argument('--num_cluster', type=str, default= '3000,5000,7000' ,help=\"number of clusters for kmeans\")\n",
    "parser.add_argument('--warmup_epoch', type=int, default= 1 ,help=\"warmup epoch for cluster\")\n",
    "parser.add_argument(\"--mlp\", type=bool, default=True, help=\"use projector or not\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "parser.add_argument('--cross_weight',type=float,default=0.001 ,help=\"cross domain weight for proto CL\")\n",
    "parser.add_argument('--num_proto_neg',type=int,default= 1280 ,help=\"intra domain weight for proto CL\")\n",
    "#pretrain\n",
    "parser.add_argument('--pretrain',default= False, action='store_true', help=\"pretrain or not\")\n",
    "parser.add_argument('--pretrain_model',type=str,default= None ,help=\"pretrain or not\")\n",
    "parser.add_argument('--joint_learn',default= False , action='store_true', help=\"pretrain epoch\")\n",
    "# parser.add_argument('--',type=bool,default=True ,help=\"use MoCo or not\")\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "# main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Data: action_thriller\n",
      " \n",
      "Number of file: 0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Data: action_romance\n",
      " \n",
      "Number of file: 0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Data: action_animation\n",
      " \n",
      "Number of file: 0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Data: action_comedy\n",
      " \n",
      "Number of file: 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "# mode = [\"no_time_ssl\",\"time_ssl_w3\",\"time_ssl_w5\",\"time_ssl_w7\",\"time_ssl_w10\",\"time_ssl_w14\"]\n",
    "# mode = [\"domain_proto_CL_pooler_crop_0.7\",\"domain_proto_CL_pooler_crop_0.6\",\"in-domain_proto_CL_pooler_crop_0.5\",\"in-domain_proto_CL_pooler\",\"in-domain_proto_CL\",\"no_ssl\"]\n",
    "# mode = [\"no_ssl\",\"augmentation_based_CL_poolingave\",\"augmentation_based_CL_dropout\",\"augmentation_based_CL_poolingave_mixed_dropout\"]\n",
    "# mode = [\"in-domain_proto_CL_pooler_crop_0.5\",\"domain_proto_CL_pooler_crop_0.6\",\"domain_proto_CL_pooler_crop_0.7\",\"in-domain_proto_CL_pooler\"]\n",
    "# mode = [\"proto_CL_only_cluster\",\"proto_only_augmentation_based_CL_dropout\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"augmentation_CL_dropout\",\"augmentation_CL_crop\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"proto_CL_only_aug_mixed_crop\",\"proto_only_augmentation_based_CL_crop\", \"proto_CL_only_aug_mixed_dropout\",\"proto_only_augmentation_based_CL_dropout\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"proto_CL_only_aug_dropout_t0.01\",\"proto_CL_only_aug_dropout_t0.1\",\"proto_CL_only_aug_dropout_t0.5\",\"no_ssl_no_graph\"]\n",
    "# mode = ['proto_only_augmentation_based_CL_dropout','proto_CL_only_aug_dropout_t0.1', \"proto_CL_only_aug_dropout_t0.01\", \"proto_CL_only_aug_dropout_t0.5\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"proto_CL_only_cluster_5_15s\",\"proto_CL_only_cluster_100_300\",\"proto_CL_only_cluster_500_1000\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_cluster_5_15_epoch10\", \"finetune_proto_CL_dropout_cluster_5_15_epoch40\",\"finetune_proto_CL_dropout_cluster_5_15_epoch70\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"no_ssl_no_graph\",\"no_ssl_no_graph_time_encode\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_cluster_500_1000_epoch10\", \"finetune_proto_CL_dropout_cluster_500_1000_epoch40\",\"finetune_proto_CL_dropout_cluster_500_1000_epoch70\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_joint_cluster_1000_2000_epoch10\", \"finetune_proto_CL_dropout_joint_cluster_1000_2000_epoch40\",\"finetune_proto_CL_dropout_joint_cluster_1000_2000_epoch70\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_joint_cluster_500_1000_epoch10\", \"finetune_proto_CL_dropout_joint_cluster_500_1000_epoch40\",\"finetune_proto_CL_dropout_joint_cluster_500_1000_epoch70\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_joint_cluster_100_300_epoch10\", \"finetune_proto_CL_dropout_joint_cluster_100_300_epoch40\",\"finetune_proto_CL_dropout_joint_cluster_100_300_epoch70\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_cluster_600_800_epoch10\", \"finetune_proto_CL_dropout_cluster_600_800_epoch40\",\"finetune_proto_CL_dropout_cluster_600_800_epoch70\",\"no_ssl_no_graph\"]\n",
    "mode = [\"finetune_proto_CL_dropout_joint_cluster_5_15_epoch40\",\"finetune_proto_CL_dropout_joint_cluster_100_300_epoch40\",\"finetune_proto_CL_dropout_joint_cluster_500_1000_epoch40\",\"finetune_proto_CL_dropout_cluster_joint_400_600_epoch40\",\n",
    "        \"finetune_proto_CL_dropout_cluster_600_800_epoch40\",\"finetune_proto_CL_dropout_cluster_800_1200_epoch40\",\"finetune_proto_CL_dropout_joint_cluster_1000_2000_epoch40\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_cluster_800_1200_epoch10\", \"finetune_proto_CL_dropout_cluster_800_1200_epoch40\",\"finetune_proto_CL_dropout_cluster_800_1200_epoch70\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_epoch40\", \"finetune_proto_CL_crop_epoch40\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_joint_epoch10\", \"finetune_proto_CL_dropout_joint_epoch40\",\"finetune_proto_CL_dropout_joint_epoch70\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_cluster_joint_100_300_mixed_epoch10\", \"finetune_proto_CL_dropout_cluster_joint_100_300_mixed_epoch20\",\"finetune_proto_CL_dropout_cluster_joint_100_300_mixed_epoch40\",\"finetune_proto_CL_dropout_cluster_joint_100_300_mixed_epoch70\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_proto_CL_dropout_cluster_joint_500_1000_mixed_epoch10\", \"finetune_proto_CL_dropout_cluster_joint_500_1000_mixed_epoch20\",\"finetune_proto_CL_dropout_cluster_joint_500_1000_mixed_epoch40\",\"finetune_proto_CL_dropout_cluster_joint_500_1000_mixed_epoch70\",\"no_ssl_no_graph\"]\n",
    "mode = [\"finetune_time_ssl_time_equivariance_joint_pretrain_epoch10\",\"finetune_time_ssl_time_equivariance_joint_pretrain_epoch20\",\"finetune_time_ssl_time_equivariance_joint_pretrain_epoch30\",\"finetune_time_ssl_time_equivariance_joint_pretrain_epoch40\",\"finetune_time_ssl_time_equivariance_joint_pretrain_epoch30\",\"finetune_time_ssl_time_equivariance_joint_pretrain_epoch40\",\"no_ssl_no_graph\"]\n",
    "mode = [\"joint_learn_NNCL\",\"joint_learn_NNCL_10\",\"joint_learn_triple_pull\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_time_ssl_joint_pretrain_epoch10\",\"finetune_time_ssl_joint_pretrain_epoch20\",\"finetune_time_ssl_time_equivariance_joint_pretrain_epoch30\",\"finetune_time_ssl_joint_pretrain_epoch40\",\"finetune_time_ssl_joint_pretrain_epoch30\",\"finetune_time_ssl_joint_pretrain_epoch40\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_time_equivariance_joint_pretrain_causality_epoch10\",\"finetune_time_equivariance_joint_pretrain_causality_epoch20\",\"finetune_time_equivariance_joint_pretrain_causality_epoch30\",\"finetune_time_equivariance_joint_pretrain_causality_epoch40\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_time_ssl_joint_pretrain_causality_epoch10\",\"finetune_time_ssl_joint_pretrain_causality_epoch20\",\"finetune_time_ssl_joint_pretrain_causality_epoch30\",\"finetune_time_ssl_joint_pretrain_causality_epoch40\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_time_equivariance_joint_pretrain_causality_epoch10\",\"finetune_time_equivariance_joint_pretrain_causality_epoch20\",\"finetune_time_equivariance_joint_pretrain_causality_epoch30\",\"finetune_time_equivariance_joint_pretrain_causality_epoch40\",\"no_ssl_no_graph\"]\n",
    "# mode = [\"finetune_time_ssl_attention_joint_pretrain_epoch10\",\"finetune_time_ssl_attention_joint_pretrain_epoch20\",\"finetune_time_ssl_attention_joint_pretrain_epoch30\",\"finetune_time_ssl_attention_joint_pretrain_epoch40\",\"no_ssl_no_graph_with_time_attention\",\"no_ssl_no_graph\"]\n",
    "mode =[\"finetune_proto_CL_dropout_cluster600_800_joint_pretrain_mixed_included_epoch10\",\"finetune_proto_CL_dropout_cluster600_800_joint_pretrain_mixed_pred_epoch10\",\"finetune_proto_CL_dropout_cluster600_800_joint_pretrain_mixed_included_epoch20\",\"finetune_proto_CL_dropout_cluster600_800_joint_pretrain_mixed_pred_epoch20\",\"finetune_proto_CL_dropout_cluster600_800_joint_pretrain_mixed_included_epoch40\",\"finetune_proto_CL_dropout_cluster600_800_joint_pretrain_mixed_pred_epoch40\",\"no_ssl_no_graph\"]\n",
    "# mode =[\"finetune_proto_CL_dropout_cluster600_800_joint_pretrain_mixed_pred_epoch10\",\"finetune_proto_CL_dropout_cluster600_800_joint_pretrain_mixed_pred_epoch20\",\"finetune_proto_CL_dropout_cluster600_800_joint_pretrain_mixed_pred_epoch40\",\"no_ssl_no_graph\"]\n",
    "# mode =[\"fairness_baseline\",\"fairness_female_Y\",\"fairness_male_Y\"]\n",
    "mode =[\"test\"]\n",
    "# data_names = [\"action_thriller\",\"action_romance\"]\n",
    "# data_names = [\"action_animation\",\"action_comedy\"]\n",
    "data_names = [\"action_thriller\",\"action_romance\",\"action_animation\",\"action_comedy\"]\n",
    "# data_names = [\"Food-Kitchen\",\"Movie-Book\"]\n",
    "target_num_file = 10.0\n",
    "for data_name in data_names:\n",
    "    print(\"-\"*50)\n",
    "    print(\"Data:\",data_name)\n",
    "    for m in mode:\n",
    "        f_list = glob.glob(f\"./saved_models/{data_name}/{m}/*\")\n",
    "        f_list = sorted(f_list,key = lambda x: int(x.split(\"/\")[-1]))\n",
    "        avg_X_res = {\n",
    "                    \"test_X_MRR\":0,\n",
    "                    \"test_X_NDCG_10\":0,\n",
    "                    \"test_X_HR_10\":0\n",
    "                }\n",
    "        avg_Y_res = {\n",
    "            \"test_Y_MRR\":0,\n",
    "            \"test_Y_NDCG_10\":0,\n",
    "            \"test_Y_HR_10\":0\n",
    "        }\n",
    "        print(\" \")\n",
    "        num_f = min(target_num_file,len(f_list))\n",
    "        for i, f in enumerate(f_list):\n",
    "            if i >= target_num_file:\n",
    "                continue\n",
    "            with open(f+\"/log.txt\", \"r\") as f:\n",
    "                data = f.readlines()[-3:-1]\n",
    "                print(data)\n",
    "                try:\n",
    "                    best_x = eval(data[0])['Best X domain']\n",
    "                    best_y = eval(data[1])['Best Y domain']\n",
    "                    for j,(k,v) in enumerate(avg_X_res.items()):\n",
    "                        avg_X_res[k] += best_x[j]\n",
    "                        \n",
    "                    for j,(k,v) in enumerate(avg_Y_res.items()):\n",
    "                        avg_Y_res[k] += best_y[j]\n",
    "                except:\n",
    "                    print(\"error:\",f)\n",
    "                    num_f-=1\n",
    "        print(\"Number of file:\",int(num_f))\n",
    "        if num_f == 0:\n",
    "            continue\n",
    "        X_res = {key: round(value / (num_f), 4) for key, value in avg_X_res.items()}\n",
    "        Y_res = {key: round(value / (num_f), 4) for key, value in avg_Y_res.items()}\n",
    "        folder_path=f\"./result/{data_name}\"\n",
    "        Path(folder_path).mkdir(parents=True, exist_ok=True)    \n",
    "        with open(f\"./result/{m}.txt\",\"w\") as f: \n",
    "            f.write(\"X domain testing result (avg over 5 seed):\"+str(X_res)+\"\\n\")\n",
    "            f.write(\"Y domain testing result (avg over 5 seed):\"+str(Y_res)+\"\\n\")\n",
    "        print(\"Mode:\",m)\n",
    "        print(X_res)\n",
    "        print(Y_res)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saved_models/action_romance/fairness_maintaskY_nonoverlap_generatenum5_20epoch_time_eval',\n",
       " './saved_models/action_romance/fairness_maintaskY_nonoverlap_generatenum3_20epoch_time_eval',\n",
       " './saved_models/action_romance/fairness_maintaskY_nonoverlap_generatenum7_20epoch_time_eval']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Data: adventure_thriller\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_baseline_Y_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1801, 'test_Y_NDCG_10': 0.198, 'test_Y_HR_10': 0.3148}\n",
      "Y male :  {'test_Y_MRR': 0.193, 'test_Y_NDCG_10': 0.2137, 'test_Y_HR_10': 0.3385}\n",
      "Y female :  {'test_Y_MRR': 0.1413, 'test_Y_NDCG_10': 0.1514, 'test_Y_HR_10': 0.2442}\n",
      "UGF: {'test_Y_MRR': 0.051699999999999996, 'test_Y_NDCG_10': 0.062299999999999994, 'test_Y_HR_10': 0.09430000000000002}\n",
      "DIF: 5.27558\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_random_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1861, 'test_Y_NDCG_10': 0.206, 'test_Y_HR_10': 0.3301}\n",
      "Y male :  {'test_Y_MRR': 0.1966, 'test_Y_NDCG_10': 0.2191, 'test_Y_HR_10': 0.3515}\n",
      "Y female :  {'test_Y_MRR': 0.1547, 'test_Y_NDCG_10': 0.1667, 'test_Y_HR_10': 0.2661}\n",
      "UGF: {'test_Y_MRR': 0.04189999999999999, 'test_Y_NDCG_10': 0.0524, 'test_Y_HR_10': 0.08539999999999998}\n",
      "DIF: 5.286019999999999\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1807, 'test_Y_NDCG_10': 0.1995, 'test_Y_HR_10': 0.3201}\n",
      "Y male :  {'test_Y_MRR': 0.1903, 'test_Y_NDCG_10': 0.2112, 'test_Y_HR_10': 0.3389}\n",
      "Y female :  {'test_Y_MRR': 0.1519, 'test_Y_NDCG_10': 0.1644, 'test_Y_HR_10': 0.2643}\n",
      "UGF: {'test_Y_MRR': 0.03839999999999999, 'test_Y_NDCG_10': 0.04680000000000001, 'test_Y_HR_10': 0.0746}\n",
      "DIF: 5.566560000000001\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Data: comedy_thriller\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_baseline_Y_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1792, 'test_Y_NDCG_10': 0.1951, 'test_Y_HR_10': 0.3068}\n",
      "Y male :  {'test_Y_MRR': 0.1835, 'test_Y_NDCG_10': 0.2002, 'test_Y_HR_10': 0.3138}\n",
      "Y female :  {'test_Y_MRR': 0.1633, 'test_Y_NDCG_10': 0.1765, 'test_Y_HR_10': 0.2811}\n",
      "UGF: {'test_Y_MRR': 0.020199999999999996, 'test_Y_NDCG_10': 0.0237, 'test_Y_HR_10': 0.03270000000000001}\n",
      "DIF: 5.51816\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_random_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1852, 'test_Y_NDCG_10': 0.2016, 'test_Y_HR_10': 0.3158}\n",
      "Y male :  {'test_Y_MRR': 0.1869, 'test_Y_NDCG_10': 0.2038, 'test_Y_HR_10': 0.32}\n",
      "Y female :  {'test_Y_MRR': 0.179, 'test_Y_NDCG_10': 0.1935, 'test_Y_HR_10': 0.3003}\n",
      "UGF: {'test_Y_MRR': 0.007900000000000018, 'test_Y_NDCG_10': 0.010300000000000004, 'test_Y_HR_10': 0.019699999999999995}\n",
      "DIF: 5.4199600000000006\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1811, 'test_Y_NDCG_10': 0.198, 'test_Y_HR_10': 0.313}\n",
      "Y male :  {'test_Y_MRR': 0.1806, 'test_Y_NDCG_10': 0.1981, 'test_Y_HR_10': 0.3159}\n",
      "Y female :  {'test_Y_MRR': 0.1828, 'test_Y_NDCG_10': 0.1976, 'test_Y_HR_10': 0.3025}\n",
      "UGF: {'test_Y_MRR': -0.0021999999999999797, 'test_Y_NDCG_10': 0.0005000000000000004, 'test_Y_HR_10': 0.013400000000000023}\n",
      "DIF: 5.310880000000001\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Data: comedy_drama\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_baseline_Y_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1618, 'test_Y_NDCG_10': 0.1845, 'test_Y_HR_10': 0.3122}\n",
      "Y male :  {'test_Y_MRR': 0.1692, 'test_Y_NDCG_10': 0.1934, 'test_Y_HR_10': 0.3254}\n",
      "Y female :  {'test_Y_MRR': 0.1444, 'test_Y_NDCG_10': 0.1637, 'test_Y_HR_10': 0.2815}\n",
      "UGF: {'test_Y_MRR': 0.02479999999999999, 'test_Y_NDCG_10': 0.029699999999999976, 'test_Y_HR_10': 0.04390000000000005}\n",
      "DIF: 5.65046\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_random_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1767, 'test_Y_NDCG_10': 0.2016, 'test_Y_HR_10': 0.3354}\n",
      "Y male :  {'test_Y_MRR': 0.1845, 'test_Y_NDCG_10': 0.2101, 'test_Y_HR_10': 0.3459}\n",
      "Y female :  {'test_Y_MRR': 0.1583, 'test_Y_NDCG_10': 0.1816, 'test_Y_HR_10': 0.311}\n",
      "UGF: {'test_Y_MRR': 0.0262, 'test_Y_NDCG_10': 0.028499999999999998, 'test_Y_HR_10': 0.03489999999999999}\n",
      "DIF: 5.5930599999999995\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1734, 'test_Y_NDCG_10': 0.1979, 'test_Y_HR_10': 0.3303}\n",
      "Y male :  {'test_Y_MRR': 0.1784, 'test_Y_NDCG_10': 0.2047, 'test_Y_HR_10': 0.3427}\n",
      "Y female :  {'test_Y_MRR': 0.1615, 'test_Y_NDCG_10': 0.1819, 'test_Y_HR_10': 0.3013}\n",
      "UGF: {'test_Y_MRR': 0.0169, 'test_Y_NDCG_10': 0.022799999999999987, 'test_Y_HR_10': 0.04139999999999999}\n",
      "DIF: 5.48056\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Data: action_comedy\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_baseline_Y_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1694, 'test_Y_NDCG_10': 0.19, 'test_Y_HR_10': 0.3096}\n",
      "Y male :  {'test_Y_MRR': 0.1815, 'test_Y_NDCG_10': 0.2043, 'test_Y_HR_10': 0.3289}\n",
      "Y female :  {'test_Y_MRR': 0.1367, 'test_Y_NDCG_10': 0.1517, 'test_Y_HR_10': 0.2576}\n",
      "UGF: {'test_Y_MRR': 0.044800000000000006, 'test_Y_NDCG_10': 0.05260000000000001, 'test_Y_HR_10': 0.07130000000000003}\n",
      "DIF: 5.788680000000001\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_random_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1798, 'test_Y_NDCG_10': 0.2031, 'test_Y_HR_10': 0.3317}\n",
      "Y male :  {'test_Y_MRR': 0.1907, 'test_Y_NDCG_10': 0.2147, 'test_Y_HR_10': 0.3443}\n",
      "Y female :  {'test_Y_MRR': 0.1502, 'test_Y_NDCG_10': 0.1717, 'test_Y_HR_10': 0.2976}\n",
      "UGF: {'test_Y_MRR': 0.04050000000000001, 'test_Y_NDCG_10': 0.04300000000000001, 'test_Y_HR_10': 0.04670000000000002}\n",
      "DIF: 5.724919999999999\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1762, 'test_Y_NDCG_10': 0.197, 'test_Y_HR_10': 0.3189}\n",
      "Y male :  {'test_Y_MRR': 0.1862, 'test_Y_NDCG_10': 0.2082, 'test_Y_HR_10': 0.3327}\n",
      "Y female :  {'test_Y_MRR': 0.1493, 'test_Y_NDCG_10': 0.167, 'test_Y_HR_10': 0.2817}\n",
      "UGF: {'test_Y_MRR': 0.036900000000000016, 'test_Y_NDCG_10': 0.04119999999999999, 'test_Y_HR_10': 0.05099999999999999}\n",
      "DIF: 5.679100000000001\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Data: thriller_romance\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_baseline_Y_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1405, 'test_Y_NDCG_10': 0.1513, 'test_Y_HR_10': 0.239}\n",
      "Y male :  {'test_Y_MRR': 0.1461, 'test_Y_NDCG_10': 0.1574, 'test_Y_HR_10': 0.2473}\n",
      "Y female :  {'test_Y_MRR': 0.1277, 'test_Y_NDCG_10': 0.1372, 'test_Y_HR_10': 0.2197}\n",
      "UGF: {'test_Y_MRR': 0.0184, 'test_Y_NDCG_10': 0.020200000000000023, 'test_Y_HR_10': 0.027599999999999986}\n",
      "DIF: 6.09402\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_random_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1496, 'test_Y_NDCG_10': 0.1617, 'test_Y_HR_10': 0.2557}\n",
      "Y male :  {'test_Y_MRR': 0.1566, 'test_Y_NDCG_10': 0.1683, 'test_Y_HR_10': 0.2624}\n",
      "Y female :  {'test_Y_MRR': 0.1336, 'test_Y_NDCG_10': 0.1464, 'test_Y_HR_10': 0.24}\n",
      "UGF: {'test_Y_MRR': 0.022999999999999993, 'test_Y_NDCG_10': 0.021900000000000003, 'test_Y_HR_10': 0.02240000000000003}\n",
      "DIF: 5.989580000000001\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1449, 'test_Y_NDCG_10': 0.159, 'test_Y_HR_10': 0.2587}\n",
      "Y male :  {'test_Y_MRR': 0.153, 'test_Y_NDCG_10': 0.1686, 'test_Y_HR_10': 0.2729}\n",
      "Y female :  {'test_Y_MRR': 0.1264, 'test_Y_NDCG_10': 0.1369, 'test_Y_HR_10': 0.226}\n",
      "UGF: {'test_Y_MRR': 0.026599999999999985, 'test_Y_NDCG_10': 0.031700000000000006, 'test_Y_HR_10': 0.04689999999999997}\n",
      "DIF: 6.04978\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Data: sci-fi_romance\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_baseline_Y_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1456, 'test_Y_NDCG_10': 0.1585, 'test_Y_HR_10': 0.2593}\n",
      "Y male :  {'test_Y_MRR': 0.1558, 'test_Y_NDCG_10': 0.169, 'test_Y_HR_10': 0.2719}\n",
      "Y female :  {'test_Y_MRR': 0.1182, 'test_Y_NDCG_10': 0.1303, 'test_Y_HR_10': 0.2252}\n",
      "UGF: {'test_Y_MRR': 0.037599999999999995, 'test_Y_NDCG_10': 0.03870000000000001, 'test_Y_HR_10': 0.046699999999999964}\n",
      "DIF: 6.650620000000001\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_random_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1626, 'test_Y_NDCG_10': 0.1786, 'test_Y_HR_10': 0.2879}\n",
      "Y male :  {'test_Y_MRR': 0.1723, 'test_Y_NDCG_10': 0.1888, 'test_Y_HR_10': 0.3001}\n",
      "Y female :  {'test_Y_MRR': 0.1364, 'test_Y_NDCG_10': 0.1512, 'test_Y_HR_10': 0.2548}\n",
      "UGF: {'test_Y_MRR': 0.035900000000000015, 'test_Y_NDCG_10': 0.037599999999999995, 'test_Y_HR_10': 0.04529999999999995}\n",
      "DIF: 6.544120000000001\n",
      "--------------------------------------------------\n",
      " \n",
      "Number of file: 5\n",
      "Mode: fairness_maintaskY_generatorAll_generatenumPoisson_20epoch_eval\n",
      "domain: Y\n",
      "Y mixed :  {'test_Y_MRR': 0.1579, 'test_Y_NDCG_10': 0.1693, 'test_Y_HR_10': 0.2669}\n",
      "Y male :  {'test_Y_MRR': 0.1697, 'test_Y_NDCG_10': 0.1812, 'test_Y_HR_10': 0.2801}\n",
      "Y female :  {'test_Y_MRR': 0.1262, 'test_Y_NDCG_10': 0.1373, 'test_Y_HR_10': 0.2311}\n",
      "UGF: {'test_Y_MRR': 0.04349999999999998, 'test_Y_NDCG_10': 0.043899999999999995, 'test_Y_HR_10': 0.049000000000000016}\n",
      "DIF: 6.571459999999999\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "# mode =[ \"fairness_Y_generator_20epoch_eval\",\"fairness_Y_generator_40epoch_eval\",\"fairness_Y_generator_60epoch_eval\"]\n",
    "# mode_name = glob.glob(\"./saved_models/action_romance/fairness_maintaskY*time_eval\")\n",
    "# mode = [x.split(\"/\")[-1] for x in mode_name] \n",
    "# mode = [\"fairness_maintaskY_generatorX_generatenum3_20epoch_eval\",\"fairness_maintaskY_generatorX_generatenum5_20epoch_eval\",\"fairness_maintaskY_generatorX_generatenum7_20epoch_eval\",\n",
    "#         \"fairness_maintaskY_generatorY_generatenum3_20epoch_eval\",\"fairness_maintaskY_generatorY_generatenum5_20epoch_eval\",\"fairness_maintaskY_generatorY_generatenum7_20epoch_eval\",\n",
    "#         \"fairness_maintaskY_generatormixed_generatenum3_20epoch_eval\",\"fairness_maintaskY_generatormixed_generatenum5_20epoch_eval\",\"fairness_maintaskY_generatormixed_generatenum7_20epoch_eval\"\n",
    "        # ]\n",
    "# mode = [\"fairness_maintaskY_generatorY_generatenum3_20epoch_eval\",\"fairness_maintaskY_generatorY_generatenum5_20epoch_eval\"]\n",
    "# mode = [\"fairness_maintaskY_generatormixed_generatenum3_20epoch_eval\",\"fairness_maintaskY_generatormixed_generatenum5_20epoch_eval\"]\n",
    "\n",
    "# mode = [\"fairness_baseline_Y_single_domain_eval\",\"fairness_baseline_Y_eval\",\"fairness_baseline_Y_single_domain_time_eval\",\"fairness_baseline_Y_time_eval\"]\n",
    "# mode = [\"fairness_baseline_Y_single_domain_eval\",\"fairness_baseline_Y_eval\",\"fairness_baseline_X_single_domain_eval\",\"fairness_baseline_X_eval\"]\n",
    "mode = [\"fairness_baseline_Y_eval\",\"fairness_maintaskY_generatorAll_generatenumPoisson_random_20epoch_eval\",\"fairness_maintaskY_generatorAll_generatenumPoisson_20epoch_eval\"]\n",
    "# mode = [\"fairness_maintaskY_usergen_same_repeat2_eval\",\"fairness_maintaskY_usergen_random_repeat2_eval\",\"fairness_baseline_Y_eval\"]\n",
    "folder_list = glob.glob(\"./fairness_dataset/Movie_lens_time/*\")\n",
    "folder_list = [x.split(\"/\")[-1] for x in folder_list]\n",
    "data_names = [x for x in folder_list if x not in [\"item_statistic.ipynb\",\"data_preprocess.py\",\"raw_data\"]]\n",
    "# data_names = [\"thriller_romance\",\"comedy_drama\"]\n",
    "# data_names = [\"adventure_romance\",'action_horror',\"action_romance\"]\n",
    "domains = [\"Y\",\"Y\",\"Y\",\"Y\"]\n",
    "target_num_file = 5.0\n",
    "for data_name in data_names:\n",
    "    print(\"-\"*50)\n",
    "    print(\"Data:\",data_name)\n",
    "    for i,m in enumerate(mode):\n",
    "        domain = domains[i]\n",
    "        f_list = glob.glob(f\"./saved_models/{data_name}/{m}/*\")\n",
    "        # print(f\"./saved_models/{data_name}/{m}/*\")\n",
    "        f_list = sorted(f_list,key = lambda x: int(x.split(\"/\")[-1]))\n",
    "        avg_X_res = {\n",
    "                    \"test_X_MRR\":0,\n",
    "                    \"test_X_NDCG_10\":0,\n",
    "                    \"test_X_HR_10\":0\n",
    "                }\n",
    "        avg_X_res_male = {\n",
    "                    \"test_X_MRR\":0,\n",
    "                    \"test_X_NDCG_10\":0,\n",
    "                    \"test_X_HR_10\":0\n",
    "                }\n",
    "        avg_X_res_female = {\n",
    "                    \"test_X_MRR\":0,\n",
    "                    \"test_X_NDCG_10\":0,\n",
    "                    \"test_X_HR_10\":0\n",
    "                }\n",
    "        avg_Y_res = {\n",
    "            \"test_Y_MRR\":0,\n",
    "            \"test_Y_NDCG_10\":0,\n",
    "            \"test_Y_HR_10\":0\n",
    "        }\n",
    "        avg_Y_res_male = {\n",
    "            \"test_Y_MRR\":0,\n",
    "            \"test_Y_NDCG_10\":0,\n",
    "            \"test_Y_HR_10\":0\n",
    "        }\n",
    "        avg_Y_res_female = {\n",
    "            \"test_Y_MRR\":0,\n",
    "            \"test_Y_NDCG_10\":0,\n",
    "            \"test_Y_HR_10\":0\n",
    "        }\n",
    "        print(\" \")\n",
    "        num_f = min(target_num_file,len(f_list))\n",
    "        js_X = []\n",
    "        js_Y = []\n",
    "        DIF = []\n",
    "        # print(m)\n",
    "        # print(f_list)\n",
    "        for i, f in enumerate(f_list):\n",
    "            if i >= target_num_file:\n",
    "                continue\n",
    "            with open(f+\"/log.txt\", \"r\") as f:\n",
    "                data = f.readlines()\n",
    "                target_data = data[1]\n",
    "                \n",
    "                # js_X.append(eval(target_data[0])['JS_divergence_X'])\n",
    "                # js_Y.append(eval(target_data[1])['JS_divergence_Y'])\n",
    "                try:\n",
    "                    DIF.append(eval(target_data)['DIF'])\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    if domain==\"X\":\n",
    "                        data = data[2:5]\n",
    "                        # print(data)\n",
    "                        best_x = eval(data[0])['Best X domain']\n",
    "                        # print(best_x)\n",
    "                        best_x_male = eval(data[1])['Best X domain male']\n",
    "                        best_x_female = eval(data[2])['Best X domain female']\n",
    "                        for j,(k,v) in enumerate(avg_X_res.items()):\n",
    "                            avg_X_res[k] += best_x[j]\n",
    "                        for j,(k,v) in enumerate(avg_X_res_male.items()):\n",
    "                            avg_X_res_male[k] += best_x_male[j]\n",
    "                        for j,(k,v) in enumerate(avg_X_res_female.items()):\n",
    "                            avg_X_res_female[k] += best_x_female[j]\n",
    "                    elif domain==\"Y\":\n",
    "                        data = data[-4:-1]\n",
    "                        # print(data)\n",
    "                        best_y = eval(data[0])['Best Y domain']\n",
    "                        best_y_male = eval(data[1])['Best Y domain male']\n",
    "                        best_y_female = eval(data[2])['Best Y domain female']\n",
    "                        for j,(k,v) in enumerate(avg_Y_res.items()):\n",
    "                            avg_Y_res[k] += best_y[j]\n",
    "                        for j,(k,v) in enumerate(avg_Y_res_male.items()):\n",
    "                            avg_Y_res_male[k] += best_y_male[j]\n",
    "                        for j,(k,v) in enumerate(avg_Y_res_female.items()):\n",
    "                            avg_Y_res_female[k] += best_y_female[j]\n",
    "                    else:\n",
    "                        best_x = eval(data[0])['Best X domain']\n",
    "                        best_y = eval(data[1])['Best Y domain']\n",
    "                        for j,(k,v) in enumerate(avg_X_res.items()):\n",
    "                            avg_X_res[k] += best_x[j]\n",
    "                            \n",
    "                        for j,(k,v) in enumerate(avg_Y_res.items()):\n",
    "                            avg_Y_res[k] += best_y[j]\n",
    "                except:\n",
    "                    print(\"error:\",f)\n",
    "                    num_f-=1\n",
    "        print(\"Number of file:\",int(num_f))\n",
    "        if num_f == 0:\n",
    "            continue\n",
    "        if domain==\"X\":\n",
    "            X_res = {key: round(value / (num_f), 4) for key, value in avg_X_res.items()}\n",
    "            X_res_male = {key: round(value / (num_f), 4) for key, value in avg_X_res_male.items()}\n",
    "            X_res_female = {key: round(value / (num_f), 4) for key, value in avg_X_res_female.items()}\n",
    "            print(\"Mode:\",m)\n",
    "            print(\"domain:\",domain)\n",
    "            # print(\"JS divergence X:\",round(sum(js_X)/len(js_X),7))\n",
    "            \n",
    "            print(\"X mixed : \",X_res)\n",
    "            print(\"X male : \",X_res_male)\n",
    "            print(\"X female : \",X_res_female)\n",
    "            UGF = {'test_X_MRR': X_res_male['test_X_MRR']-X_res_female['test_X_MRR'],'test_X_NDCG_10': X_res_male['test_X_NDCG_10']-X_res_female['test_X_NDCG_10'],'test_X_HR_10': X_res_male['test_X_HR_10']-X_res_female['test_X_HR_10']}\n",
    "            print(\"UGF:\",UGF)\n",
    "            try:\n",
    "                print(\"DIF:\",sum(DIF)/len(DIF))\n",
    "            except:\n",
    "                print(\"No DIF !!\")\n",
    "        elif domain==\"Y\":\n",
    "            Y_res = {key: round(value / (num_f), 4) for key, value in avg_Y_res.items()}\n",
    "            Y_res_male = {key: round(value / (num_f), 4) for key, value in avg_Y_res_male.items()}\n",
    "            Y_res_female = {key: round(value / (num_f), 4) for key, value in avg_Y_res_female.items()}\n",
    "            print(\"Mode:\",m)\n",
    "            print(\"domain:\",domain)\n",
    "            # print(\"JS divergence Y:\",round(sum(js_Y)/len(js_Y),7))\n",
    "            print(\"Y mixed : \",Y_res)\n",
    "            print(\"Y male : \",Y_res_male)\n",
    "            print(\"Y female : \",Y_res_female)\n",
    "            UGF = {'test_Y_MRR': Y_res_male['test_Y_MRR']-Y_res_female['test_Y_MRR'],'test_Y_NDCG_10': Y_res_male['test_Y_NDCG_10']-Y_res_female['test_Y_NDCG_10'],'test_Y_HR_10': Y_res_male['test_Y_HR_10']-Y_res_female['test_Y_HR_10']}\n",
    "            print(\"UGF:\",UGF)\n",
    "            try:\n",
    "                print(\"DIF:\",sum(DIF)/len(DIF))\n",
    "            except:\n",
    "                print(\"No DIF !!\")\n",
    "        else:\n",
    "            X_res = {key: round(value / (num_f), 4) for key, value in avg_X_res.items()}\n",
    "            Y_res = {key: round(value / (num_f), 4) for key, value in avg_Y_res.items()}\n",
    "            folder_path=f\"./result/{data_name}\"\n",
    "            Path(folder_path).mkdir(parents=True, exist_ok=True)    \n",
    "            with open(f\"./result/{m}.txt\",\"w\") as f: \n",
    "                f.write(\"X domain testing result (avg over 5 seed):\"+str(X_res)+\"\\n\")\n",
    "                f.write(\"Y domain testing result (avg over 5 seed):\"+str(Y_res)+\"\\n\")\n",
    "            print(\"Mode:\",m)\n",
    "            print(X_res)\n",
    "            print(Y_res)\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 19, 18, 13, 15,  7,  1,  0,  7,  6])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming we have a tensor of shape [20, 10]\n",
    "tensor = torch.randint(20, (20,10))\n",
    "\n",
    "# Randomly selecting one value from each column\n",
    "indices = torch.randint(20, (10,))  # Generate random indices for each column\n",
    "selected_values = tensor[indices, torch.arange(10)]  # Use advanced indexing to select values\n",
    "\n",
    "selected_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "input1 = torch.randn(100, 128)\n",
    "input2 = torch.randn(100, 128)\n",
    "output = F.cosine_similarity(input1, input2)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  2,  3, 19,  7, 18, 14, 18, 17,  9],\n",
       "        [ 9,  0, 19,  7, 15,  6,  8,  3,  7,  8],\n",
       "        [14, 19,  6, 12, 10, 19,  7,  5,  3,  5],\n",
       "        [13,  4,  3, 17,  5, 16, 19, 13,  4, 15],\n",
       "        [10,  3, 18,  2, 17,  5, 11,  6,  7, 17],\n",
       "        [11, 12,  8,  9,  3, 13,  1,  4, 11,  3],\n",
       "        [ 4,  2, 15,  5, 15, 11, 19, 12, 11, 12],\n",
       "        [15, 13,  3,  5, 11,  7, 18,  0,  5, 19],\n",
       "        [ 8,  9, 14,  8,  0, 11,  7,  5,  1,  4],\n",
       "        [ 1,  9,  4,  1,  3, 11, 13, 11, 14,  6],\n",
       "        [14, 11,  8,  3, 10, 14, 14,  2,  7,  7],\n",
       "        [11,  8,  4, 13,  1, 14,  5, 13,  2,  3],\n",
       "        [19, 10, 18, 11, 15,  7, 15,  3,  1, 10],\n",
       "        [ 9,  4,  6, 10,  5,  2,  8,  7,  1,  7],\n",
       "        [13,  3, 15,  6, 13,  0, 14,  1,  3, 16],\n",
       "        [19, 13,  4,  2,  3, 17,  1,  1, 17, 10],\n",
       "        [16,  8,  8, 19,  8, 15,  9, 12,  4,  2],\n",
       "        [ 4,  7, 17, 13, 14, 17,  4,  6, 14, 16],\n",
       "        [ 2, 18,  3,  5, 16,  1,  1, 17,  0, 18],\n",
       "        [11, 13,  1, 14,  9,  8, 17,  5, 13, 17]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
